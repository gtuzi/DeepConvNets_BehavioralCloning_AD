{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2017, Gerti Tuzi\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#     * Neither the name of Gerti Tuzi nor the\n",
    "#       names of its contributors may be used to endorse or promote products\n",
    "#       derived from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\n",
    "# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n",
    "# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Regression Model Training\n",
    "\n",
    "## Data\n",
    "\n",
    "#### Load Logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "# -------------------------\n",
    "# Load data from the csv file\n",
    "loglines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        loglines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Split Train/Validation/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train Samples: 72912\n",
      "Num Valid Samples: 5208\n",
      "Num Test Samples: 8668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "validation_portion = 0.3\n",
    "# Log lines are our references to the samples\n",
    "train_loglines, test_loglines = train_test_split(loglines, test_size=0.333, random_state=0)\n",
    "train_loglines, validation_loglines = train_test_split(train_loglines, test_size=validation_portion, random_state=0)\n",
    "\n",
    "num_cams = 3\n",
    "# 3 cameras * (1 original + 1 horizontal flip)\n",
    "n_train = len(train_loglines) * 2 * num_cams\n",
    "n_valid = len(validation_loglines)\n",
    "n_test = len(test_loglines)\n",
    "\n",
    "print('Num Train Samples: ' + str(n_train))\n",
    "print('Num Valid Samples: ' + str(n_valid))\n",
    "print('Num Test Samples: ' + str(n_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from GTRegressionModel import GTRegressionModel\n",
    "import math, os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,LearningRateScheduler\n",
    "from DataGenerators import train_generator_center, train_generator_3, generator\n",
    "\n",
    "mode = 'angle'\n",
    "\n",
    "model_dir = 'model'\n",
    "if mode == 'angle':\n",
    "    best_model = model_dir + '/model_angle.h5'\n",
    "elif mode == 'velocity':\n",
    "    best_model = model_dir + '/model_velocity.h5'\n",
    "else:\n",
    "    raise Exception('Training mode must be specified: Y is what measure ?')\n",
    "    \n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Training parameters\n",
    "Initial_LR = 0.001\n",
    "Train_batch_size = 90 # multiples of 6\n",
    "Valid_batch_size = 32\n",
    "Test_batch_size = 32\n",
    "Dropout_Rate = 0.2\n",
    "Max_No_Epochs = 35\n",
    "\n",
    "\n",
    "Num_Batches_Per_Train_Epoch = int(n_train/Train_batch_size)\n",
    "if (n_train  % Train_batch_size) > 0:\n",
    "    Num_Batches_Per_Train_Epoch += 1\n",
    "\n",
    "    \n",
    "Num_Batches_Per_Valid_Epoch = int(n_valid/Valid_batch_size)\n",
    "if (n_valid  % Valid_batch_size) > 0:\n",
    "    Num_Batches_Per_Valid_Epoch += 1\n",
    "\n",
    "    \n",
    "Num_Batches_Per_Test_Epoch = int(n_test/Test_batch_size)\n",
    "if (n_test  % Test_batch_size) > 0:\n",
    "    Num_Batches_Per_Test_Epoch += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Augmentation\n",
    "3 cameras are placed on the vehicle. Center camera is used for online driving. Left/Right cameras emulate (augment)  horizontal drifts (shifts).\n",
    "\n",
    "Data is augmented in the following ways:\n",
    "* Horizontal flip: simple left-right flip of the image, and a sign-change of the target steering angle\n",
    "* Using Left/Right camera images as shifted center images. An offset is applied to the steering angle (data label) when using these camera images, in the following way: positive steering (counter-clockwise) for the left-camera, negative steering (clockwise) for the right-camera.\n",
    "* Random artificial horizontal shifts during training: shift the image in proportion to the size of the width. Adjust the target steering angle in proportion of the shift: `<new_angle> = <old_angle> + <shift_proportion> x <old_angle>`\n",
    "* Random vertical shifts/rotations/shears: random shifts which do not affect the angle label. **We should not apply too much vertical shifts** because we're clipping the top and bottom of the image before feeding it into the NN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data generators\n",
    "Using data generators because the dataset is very large\n",
    "\n",
    "**Train generator** performs the following transformations:\n",
    "* Horizontal shifts: as a portion of the size of the width of the image. Label target is adjusted according to the propotion of the shift: \n",
    "* Vertical shifts: as a proportion of height. Angle size is not changed\n",
    "* Rotation/Shear rotation: in angle degrees.\n",
    "* Shuffle the data during training\n",
    "* Outputs batches of data\n",
    "\n",
    "\n",
    "**Validation/Test genrators**\n",
    "* Output only the center camera data. The label (steering angle) is not modified.\n",
    "* One sample per call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_gen = train_generator_3(train_loglines, sixth_of_batch_size=int(Train_batch_size/6.),\n",
    "                            horizontal_augment=True, horizontal_shift_range=0.05,\n",
    "                            vertical_augment=True, vertical_shift_range=0.05,\n",
    "                            rotation_augment=True, rotation_range=5.,\n",
    "                            shear_augment=True, shear_range=5.,\n",
    "                            do_shuffle=True, mode = mode)\n",
    "test_gen = generator(loglines=test_loglines, batch_size=Test_batch_size, mode=mode)\n",
    "valid_gen = generator(loglines=validation_loglines, batch_size=Valid_batch_size, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Callbacks\n",
    "\n",
    "Callbacks used for learning rate decay, early termination, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    # Number of batches before learning rate drops by a 'drop_factor'\n",
    "    batch_count_drop_step = 10000.0\n",
    "    drop_factor = 0.1\n",
    "\n",
    "    batch_count = float(epoch*Num_Batches_Per_Train_Epoch)\n",
    "    pow_factor = (math.pow(drop_factor, math.floor(batch_count/(batch_count_drop_step))))\n",
    "    lrate = Initial_LR*pow_factor\n",
    "\n",
    "    print(\"Epoch: {0} - Batch_count: {1} - Pow Fact: {2:0.3f} - lrate: {3:0.6f}\".\n",
    "          format(epoch, batch_count, pow_factor, lrate))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "\n",
    "# The best model here is determined by the monitor parameter.\n",
    "# It can be the best based on training values, or validataion (prefixed by val_)\n",
    "best_val_mse_checkpoint = ModelCheckpoint(best_model,\n",
    "                             monitor= 'val_loss', # This determines what gets saved (val_acc: validation accuracy)\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only= False, # If false the whole model is saved\n",
    "                             mode='auto')\n",
    "\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              #  minimum change in the monitored quantity to qualify as an improvement,\n",
    "                              # i.e. an absolute change of less than min_delta, will count as no improvement.\n",
    "                              min_delta=0.0,\n",
    "                              # number of epochs with no improvement after\n",
    "                              # which training will be stopped\n",
    "                              patience=30,\n",
    "                              verbose=1,\n",
    "                              mode='auto')\n",
    "\n",
    "callbacks_list = [best_val_mse_checkpoint, earlystopping, lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = GTRegressionModel(input_shape=(160, 320, 3), drop_prob=Dropout_Rate)\n",
    "\n",
    "# Minimizing the error between the logits and the\n",
    "# continuous value of the labels (steering wheel angle)\n",
    "# we get a regression fit (as opposed to classification)\n",
    "# Using the loss function MSE - the same loss function\n",
    "# used in regular regression\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train Model\n",
    "Train the model with custom generators above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Parameters **********************\n",
      "- Train Batch_Size : 90\n",
      "- Max_No_Epochs: 35\n",
      "- Init_LR: 0.001\n",
      "- Num_Batches_Per_Epoch: 811\n",
      "- Dropout_Rate: 0.200\n",
      "- Training Mode: angle\n",
      "***************************************************\n",
      "Epoch: 0 - Batch_count: 0.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 1/35\n",
      "Epoch 00000: val_loss improved from inf to 0.07998, saving model to model/model_angle.h5\n",
      "1558s - loss: 0.1256 - val_loss: 0.0800\n",
      "Epoch: 1 - Batch_count: 811.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 2/35\n",
      "Epoch 00001: val_loss improved from 0.07998 to 0.07348, saving model to model/model_angle.h5\n",
      "1534s - loss: 0.1018 - val_loss: 0.0735\n",
      "Epoch: 2 - Batch_count: 1622.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 3/35\n",
      "Epoch 00002: val_loss improved from 0.07348 to 0.07075, saving model to model/model_angle.h5\n",
      "1533s - loss: 0.0960 - val_loss: 0.0708\n",
      "Epoch: 3 - Batch_count: 2433.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 4/35\n",
      "Epoch 00003: val_loss improved from 0.07075 to 0.06940, saving model to model/model_angle.h5\n",
      "1532s - loss: 0.0929 - val_loss: 0.0694\n",
      "Epoch: 4 - Batch_count: 3244.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 5/35\n",
      "Epoch 00004: val_loss improved from 0.06940 to 0.06845, saving model to model/model_angle.h5\n",
      "1533s - loss: 0.0915 - val_loss: 0.0685\n",
      "Epoch: 5 - Batch_count: 4055.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 6/35\n",
      "Epoch 00005: val_loss did not improve\n",
      "1532s - loss: 0.0900 - val_loss: 0.0687\n",
      "Epoch: 6 - Batch_count: 4866.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 7/35\n",
      "Epoch 00006: val_loss improved from 0.06845 to 0.06722, saving model to model/model_angle.h5\n",
      "1532s - loss: 0.0890 - val_loss: 0.0672\n",
      "Epoch: 7 - Batch_count: 5677.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 8/35\n",
      "Epoch 00007: val_loss improved from 0.06722 to 0.06709, saving model to model/model_angle.h5\n",
      "1532s - loss: 0.0879 - val_loss: 0.0671\n",
      "Epoch: 8 - Batch_count: 6488.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 9/35\n",
      "Epoch 00008: val_loss did not improve\n",
      "1532s - loss: 0.0870 - val_loss: 0.0700\n",
      "Epoch: 9 - Batch_count: 7299.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 10/35\n",
      "Epoch 00009: val_loss improved from 0.06709 to 0.06618, saving model to model/model_angle.h5\n",
      "1532s - loss: 0.0870 - val_loss: 0.0662\n",
      "Epoch: 10 - Batch_count: 8110.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 11/35\n",
      "Epoch 00010: val_loss did not improve\n",
      "1533s - loss: 0.0860 - val_loss: 0.0677\n",
      "Epoch: 11 - Batch_count: 8921.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 12/35\n",
      "Epoch 00011: val_loss did not improve\n",
      "1534s - loss: 0.0857 - val_loss: 0.0670\n",
      "Epoch: 12 - Batch_count: 9732.0 - Pow Fact: 1.000 - lrate: 0.001000\n",
      "Epoch 13/35\n",
      "Epoch 00012: val_loss improved from 0.06618 to 0.06600, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0842 - val_loss: 0.0660\n",
      "Epoch: 13 - Batch_count: 10543.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 14/35\n",
      "Epoch 00013: val_loss improved from 0.06600 to 0.06380, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0813 - val_loss: 0.0638\n",
      "Epoch: 14 - Batch_count: 11354.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 15/35\n",
      "Epoch 00014: val_loss did not improve\n",
      "1542s - loss: 0.0806 - val_loss: 0.0640\n",
      "Epoch: 15 - Batch_count: 12165.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 16/35\n",
      "Epoch 00015: val_loss did not improve\n",
      "1539s - loss: 0.0812 - val_loss: 0.0641\n",
      "Epoch: 16 - Batch_count: 12976.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 17/35\n",
      "Epoch 00016: val_loss did not improve\n",
      "1548s - loss: 0.0808 - val_loss: 0.0641\n",
      "Epoch: 17 - Batch_count: 13787.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 18/35\n",
      "Epoch 00017: val_loss did not improve\n",
      "1556s - loss: 0.0801 - val_loss: 0.0640\n",
      "Epoch: 18 - Batch_count: 14598.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 19/35\n",
      "Epoch 00018: val_loss did not improve\n",
      "1557s - loss: 0.0804 - val_loss: 0.0642\n",
      "Epoch: 19 - Batch_count: 15409.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 20/35\n",
      "Epoch 00019: val_loss improved from 0.06380 to 0.06376, saving model to model/model_angle.h5\n",
      "1545s - loss: 0.0800 - val_loss: 0.0638\n",
      "Epoch: 20 - Batch_count: 16220.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 21/35\n",
      "Epoch 00020: val_loss improved from 0.06376 to 0.06365, saving model to model/model_angle.h5\n",
      "1543s - loss: 0.0800 - val_loss: 0.0637\n",
      "Epoch: 21 - Batch_count: 17031.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 22/35\n",
      "Epoch 00021: val_loss did not improve\n",
      "1538s - loss: 0.0796 - val_loss: 0.0637\n",
      "Epoch: 22 - Batch_count: 17842.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 23/35\n",
      "Epoch 00022: val_loss improved from 0.06365 to 0.06346, saving model to model/model_angle.h5\n",
      "1537s - loss: 0.0797 - val_loss: 0.0635\n",
      "Epoch: 23 - Batch_count: 18653.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 24/35\n",
      "Epoch 00023: val_loss did not improve\n",
      "1539s - loss: 0.0797 - val_loss: 0.0639\n",
      "Epoch: 24 - Batch_count: 19464.0 - Pow Fact: 0.100 - lrate: 0.000100\n",
      "Epoch 25/35\n",
      "Epoch 00024: val_loss did not improve\n",
      "1538s - loss: 0.0796 - val_loss: 0.0637\n",
      "Epoch: 25 - Batch_count: 20275.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 26/35\n",
      "Epoch 00025: val_loss improved from 0.06346 to 0.06325, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0798 - val_loss: 0.0632\n",
      "Epoch: 26 - Batch_count: 21086.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 27/35\n",
      "Epoch 00026: val_loss did not improve\n",
      "1538s - loss: 0.0792 - val_loss: 0.0633\n",
      "Epoch: 27 - Batch_count: 21897.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 28/35\n",
      "Epoch 00027: val_loss improved from 0.06325 to 0.06317, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0797 - val_loss: 0.0632\n",
      "Epoch: 28 - Batch_count: 22708.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 29/35\n",
      "Epoch 00028: val_loss improved from 0.06317 to 0.06314, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0799 - val_loss: 0.0631\n",
      "Epoch: 29 - Batch_count: 23519.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 30/35\n",
      "Epoch 00029: val_loss improved from 0.06314 to 0.06312, saving model to model/model_angle.h5\n",
      "1538s - loss: 0.0790 - val_loss: 0.0631\n",
      "Epoch: 30 - Batch_count: 24330.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 31/35\n",
      "Epoch 00030: val_loss did not improve\n",
      "1538s - loss: 0.0794 - val_loss: 0.0631\n",
      "Epoch: 31 - Batch_count: 25141.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 32/35\n",
      "Epoch 00031: val_loss improved from 0.06312 to 0.06310, saving model to model/model_angle.h5\n",
      "1539s - loss: 0.0793 - val_loss: 0.0631\n",
      "Epoch: 32 - Batch_count: 25952.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 33/35\n",
      "Epoch 00032: val_loss did not improve\n",
      "1538s - loss: 0.0792 - val_loss: 0.0632\n",
      "Epoch: 33 - Batch_count: 26763.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 34/35\n",
      "Epoch 00033: val_loss improved from 0.06310 to 0.06309, saving model to model/model_angle.h5\n",
      "1539s - loss: 0.0794 - val_loss: 0.0631\n",
      "Epoch: 34 - Batch_count: 27574.0 - Pow Fact: 0.010 - lrate: 0.000010\n",
      "Epoch 35/35\n",
      "Epoch 00034: val_loss did not improve\n",
      "1539s - loss: 0.0797 - val_loss: 0.0632\n"
     ]
    }
   ],
   "source": [
    "print(\"************** Parameters **********************\")\n",
    "print ((\"- Train Batch_Size : {0}\\n- Max_No_Epochs: {1}\\n\" +\n",
    "        \"- Init_LR: {2}\\n- Num_Batches_Per_Epoch: {3}\\n\" +\n",
    "        \"- Dropout_Rate: {4:0.3f}\\n\"+ \n",
    "        \"- Training Mode: {5}\").format(\n",
    "    Train_batch_size, Max_No_Epochs,\n",
    "    Initial_LR,Num_Batches_Per_Train_Epoch,Dropout_Rate, mode))\n",
    "print(\"***************************************************\")\n",
    "\n",
    "\n",
    "train_history = model.fit_generator(generator=train_gen, steps_per_epoch= Num_Batches_Per_Train_Epoch,\n",
    "                    validation_data=valid_gen, validation_steps = Num_Batches_Per_Valid_Epoch,\n",
    "                    epochs=Max_No_Epochs,\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if mode == 'angle':\n",
    "    model.save( model_dir + '/final_model_angle.h5')\n",
    "elif mode == 'velocity':\n",
    "    model.save( model_dir + '/final_model_velocity.h5')    \n",
    "\n",
    "    \n",
    "\n",
    "# Save history\n",
    "import pickle\n",
    "with open('train_history.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.06\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "scores = model.evaluate_generator(generator=test_gen, steps=Num_Batches_Per_Test_Epoch)\n",
    "print(\"Test MSE: {0:.2f}\".format(scores))\n",
    "\n",
    "print(model.metrics_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
